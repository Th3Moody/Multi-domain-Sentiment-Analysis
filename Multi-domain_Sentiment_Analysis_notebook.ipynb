{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Task4_Bonus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Downloading Dataset (Google Colab Environment)\n",
        "! wget \"https://www.cs.jhu.edu/~mdredze/datasets/sentiment/domain_sentiment_data.tar.gz\"\n",
        "! tar -xzf \"/content/domain_sentiment_data.tar.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ska8xu3n6FZ",
        "outputId": "f6f4e650-ec78-425b-f6f0-472693039549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-02 12:22:18--  https://www.cs.jhu.edu/~mdredze/datasets/sentiment/domain_sentiment_data.tar.gz\n",
            "Resolving www.cs.jhu.edu (www.cs.jhu.edu)... 128.220.13.64\n",
            "Connecting to www.cs.jhu.edu (www.cs.jhu.edu)|128.220.13.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30586147 (29M) [application/x-gzip]\n",
            "Saving to: ‘domain_sentiment_data.tar.gz’\n",
            "\n",
            "domain_sentiment_da 100%[===================>]  29.17M  20.0MB/s    in 1.5s    \n",
            "\n",
            "2022-06-02 12:22:20 (20.0 MB/s) - ‘domain_sentiment_data.tar.gz’ saved [30586147/30586147]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Input, Dense, Embedding, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "C7Gx_NRRw_4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbf214a-d16a-4033-b9fa-59270490b232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def clean_sentence(sentence: str) -> list:\n",
        "  # Remove the review tag\n",
        "  tags = re.compile(\"(<review_text>|<\\/review_text>)\")\n",
        "  sentence = re.sub(tags, '', sentence)\n",
        "\n",
        "  # lower case\n",
        "  sentence = sentence.lower()\n",
        "\n",
        "  # Remove emails and urls\n",
        "  email_urls = re.compile(\"(\\bhttp.+? | \\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b)\")\n",
        "  sentence = re.sub(email_urls, '', sentence)\n",
        "\n",
        "  # Some used '@' to hide offensive words (bla -> bl@)\n",
        "  ats = re.compile('@')\n",
        "  sentence = re.sub(ats, 'a', sentence)\n",
        "\n",
        "  # Remove Punctuation \n",
        "  # punc = re.compile(\"[!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+,\\-\\.\\/\\:;<=>\\?\\[\\\\\\]\\^_`\\{\\|\\}\\~]\")\n",
        "  punc = re.compile(\"[^\\w\\s(\\w+\\-\\w+)]\")\n",
        "  sentence = re.sub(punc, '', sentence)\n",
        "\n",
        "  # Remove stopwords and tokenize\n",
        "  # sentence = sentence.split(sep=' ')\n",
        "  sentence = word_tokenize(sentence)\n",
        "  sentence = [word for word in sentence if not word in stopwords.words()]\n",
        "\n",
        "  # Stemming (Returning to root)\n",
        "  # stemmer = PorterStemmer()\n",
        "  # sentence = [stemmer.stem(word) for word in sentence]\n",
        "\n",
        "\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "q9HOr-APL8pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read files\n",
        "path = \"/content/sorted_data_acl/\"\n",
        "regex_review = re.compile(\"<review_text>.+?<\\/review_text>\", flags=re.DOTALL)\n",
        "\n",
        "# Training Data\n",
        "folders = [\"books\",\"dvd\",\"electronics\"]\n",
        "x_train = list()\n",
        "y_train = list()\n",
        "print('Reading Train Data')\n",
        "for folder in folders:\n",
        "  temp = open(path+folder+\"/negative.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Negative reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_train.append(clean_sentence(sentence))\n",
        "    y_train.append(0)\n",
        "  \n",
        "\n",
        "  temp = open(path+folder+\"/positive.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Positive reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_train.append(clean_sentence(sentence))\n",
        "    y_train.append(1)\n",
        "  \n",
        "\n",
        "\n",
        "# Test data\n",
        "folders = [\"kitchen_&_housewares\"]\n",
        "x_test = list()\n",
        "y_test = list()\n",
        "print('Reading Test Data')\n",
        "for folder in folders:\n",
        "  temp = open(path+folder+\"/negative.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Negative reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_test.append(clean_sentence(sentence))\n",
        "    y_test.append(0)\n",
        "  \n",
        "\n",
        "  temp = open(path+folder+\"/positive.review\", 'r').read() # Read the file\n",
        "  temp = re.findall(regex_review, temp) # Get reviews\n",
        "  print(\"Reading\",len(temp),\"Positive reviews from\",folder)\n",
        "  for sentence in temp:\n",
        "    x_test.append(clean_sentence(sentence))\n",
        "    y_test.append(1)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYHRMEGDdMYO",
        "outputId": "8bc7833e-191a-4af6-8ee1-6d8fd139c728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Train Data\n",
            "Reading 1000 Negative reviews from books\n",
            "Reading 1000 Positive reviews from books\n",
            "Reading 1000 Negative reviews from dvd\n",
            "Reading 1000 Positive reviews from dvd\n",
            "Reading 1000 Negative reviews from electronics\n",
            "Reading 1000 Positive reviews from electronics\n",
            "Reading Test Data\n",
            "Reading 1000 Negative reviews from kitchen_&_housewares\n",
            "Reading 1000 Positive reviews from kitchen_&_housewares\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It took more than one hour, saving them (T_T)\n",
        "\n",
        "temp_file = open('x_train','wb')\n",
        "save_x_train = dump(x_train, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('y_train','wb')\n",
        "save_y_train = dump(y_train, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('x_test','wb')\n",
        "save_x_test = dump(x_test, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('y_test','wb')\n",
        "save_y_test = dump(y_test, temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "\n",
        "# Loading them\n",
        "\n",
        "# temp_file = open('x_train', 'rb')\n",
        "# x_train = load(temp_file)\n",
        "# temp_file.close()\n",
        "\n",
        "# temp_file = open('y_train', 'rb')\n",
        "# y_train = load(temp_file)\n",
        "# temp_file.close()\n",
        "\n",
        "# temp_file = open('x_test', 'rb')\n",
        "# x_test = load(temp_file)\n",
        "# temp_file.close()\n",
        "\n",
        "# temp_file = open('y_test', 'rb')\n",
        "# y_test = load(temp_file)\n",
        "# temp_file.close()"
      ],
      "metadata": {
        "id": "CO0QMp27xjeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some investigations\n",
        "lengths = [len(sentence) for sentence in x_train]\n",
        "lengths.sort()\n",
        "print(\"Max size:\", max(lengths))\n",
        "print(\"Min size:\", min(lengths))\n",
        "print(\"Top 10 sizes:\",lengths[-20:])\n",
        "counts,bins,_ = plt.hist(lengths,bins=[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 300, 2000])\n",
        "for i in range(len(counts)-1):\n",
        "  print('From ',bins[i],'to',bins[i+1],':',counts[i])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Most reviews are less than 100 words (4614), and 918 reviews are less than 200 but greater than 100\n",
        "# Lets take max sequence length as 125 (using weighted mean and neglecting reviews above 300 words)\n",
        "# or 175 if we took all review sizes into consideration"
      ],
      "metadata": {
        "id": "UA6tYdbrwmux",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "f86f79e7-f133-4a16-bd71-108ba2d05c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max size: 1942\n",
            "Min size: 1\n",
            "Top 10 sizes: [586, 589, 591, 596, 597, 599, 622, 631, 643, 674, 674, 678, 703, 711, 711, 750, 752, 822, 1196, 1942]\n",
            "From  0 to 20 : 955.0\n",
            "From  20 to 40 : 1422.0\n",
            "From  40 to 60 : 1121.0\n",
            "From  60 to 80 : 657.0\n",
            "From  80 to 100 : 459.0\n",
            "From  100 to 120 : 305.0\n",
            "From  120 to 140 : 237.0\n",
            "From  140 to 160 : 152.0\n",
            "From  160 to 180 : 112.0\n",
            "From  180 to 200 : 112.0\n",
            "From  200 to 300 : 302.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATP0lEQVR4nO3df4zk9X3f8eerEGjtJL4DtpTeXbvn5OqKRm19XWEqJ1YUIjjA9dE2sUBRuThIp6i4tUsq5xxLIUoUCZo2NKgp0SVcfVQU7Dq2OBVSfMVOrUqFeMGYn8asMZg7HdzGYJyWJg7Ju3/M58iw3r1jdmZn4T7PhzSa7/fz/cz3+57vzL7mu5+Z70yqCklSH/7SehcgSZoeQ1+SOmLoS1JHDH1J6oihL0kdOXW9Czies846q2ZnZ9e7DEl6U7n//vv/sKpmllv2hg792dlZ5ufn17sMSXpTSfLMSssc3pGkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6cMPST7EtyNMkjyyz7uSSV5Kw2nyQ3JllI8lCS7UN9dyV5sl12TfZunNjsnjtfvUhSr17Pkf7HgR1LG5NsAS4EvjHUfDGwrV12Aze1vmcA1wLvAs4Drk2ycZzCJUmjO2HoV9UXgBeWWXQD8BFg+PcWdwK31MC9wIYk5wAXAQer6oWqehE4yDIvJJKktbWqMf0kO4HDVfXlJYs2Ac8OzR9qbSu1L7fu3Unmk8wvLi6upjxJ0gpGDv0kbwF+AfjFyZcDVbW3quaqam5mZtlvBpUkrdJqjvR/ANgKfDnJ08Bm4IEkfw04DGwZ6ru5ta3ULkmaopFDv6oerqq/WlWzVTXLYKhme1U9BxwArmyf4jkfeKmqjgB3Axcm2djewL2wtUmSpuj1fGTzNuB/A+9IcijJVcfpfhfwFLAA/DbwzwGq6gXgV4AvtssvtzZJ0hSd8JezquqKEyyfHZou4OoV+u0D9o1YnyRpgjwjV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTlh6CfZl+RokkeG2n4tyVeSPJTkM0k2DC37aJKFJE8kuWiofUdrW0iyZ/J3RZJ0Iq/nSP/jwI4lbQeBH6qqvwt8FfgoQJJzgcuBv9Nu8x+TnJLkFOA3gYuBc4ErWl9J0hSdMPSr6gvAC0vaPltVr7TZe4HNbXoncHtV/UlVfR1YAM5rl4WqeqqqvgPc3vpKkqZoEmP6PwP8XpveBDw7tOxQa1up/bsk2Z1kPsn84uLiBMqTJB0zVugn+RjwCnDrZMqBqtpbVXNVNTczMzOp1UqSgFNXe8MkPw28F7igqqo1Hwa2DHXb3No4TrskaUpWdaSfZAfwEeB9VfXy0KIDwOVJTk+yFdgG/AHwRWBbkq1JTmPwZu+B8UqXJI3qhEf6SW4DfhQ4K8kh4FoGn9Y5HTiYBODeqvrZqno0ySeBxxgM+1xdVX/W1vNB4G7gFGBfVT26BvdHknQcJwz9qrpimeabj9P/V4FfXab9LuCukaqTJE2UZ+RKUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjqz6jNw3s9k9d746/fR1l65jJZI0XR7pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdeSEoZ9kX5KjSR4ZajsjycEkT7brja09SW5MspDkoSTbh26zq/V/Msmutbk7kqTjeT1H+h8Hdixp2wPcU1XbgHvaPMDFwLZ22Q3cBIMXCeBa4F3AecC1x14oJEnTc8LQr6ovAC8sad4J7G/T+4HLhtpvqYF7gQ1JzgEuAg5W1QtV9SJwkO9+IZEkrbHVjumfXVVH2vRzwNltehPw7FC/Q61tpfbvkmR3kvkk84uLi6ssT5K0nLHfyK2qAmoCtRxb396qmququZmZmUmtVpLE6kP/+TZsQ7s+2toPA1uG+m1ubSu1S5KmaLWhfwA49gmcXcAdQ+1Xtk/xnA+81IaB7gYuTLKxvYF7YWuTJE3RCX8YPcltwI8CZyU5xOBTONcBn0xyFfAM8P7W/S7gEmABeBn4AEBVvZDkV4Avtn6/XFVL3xyWJK2xE4Z+VV2xwqILlulbwNUrrGcfsG+k6iRJE+UZuZLUkRMe6b+Zze65c71LkKQ3FI/0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZKzQT/Kvkjya5JEktyX5y0m2JrkvyUKSTyQ5rfU9vc0vtOWzk7gDkqTXb9Whn2QT8C+Buar6IeAU4HLgeuCGqvpB4EXgqnaTq4AXW/sNrZ8kaYrGHd45FfgrSU4F3gIcAX4M+FRbvh+4rE3vbPO05RckyZjblySNYNWhX1WHgX8LfINB2L8E3A98q6pead0OAZva9Cbg2XbbV1r/M5euN8nuJPNJ5hcXF1dbniRpGeMM72xkcPS+FfjrwFuBHeMWVFV7q2ququZmZmbGXZ0kacg4wzs/Dny9qhar6k+BTwPvBja04R6AzcDhNn0Y2ALQlr8N+OYY25ckjWic0P8GcH6St7Sx+QuAx4DPAz/R+uwC7mjTB9o8bfnnqqrG2L4kaUTjjOnfx+AN2QeAh9u69gI/D1yTZIHBmP3N7SY3A2e29muAPWPULUlahVNP3GVlVXUtcO2S5qeA85bp+8fAT46zPUnSeDwjV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6M9X36J4PZPXe+Ov30dZeuYyWStPY80pekjhj6ktQRQ1+SOmLoS1JHxgr9JBuSfCrJV5I8nuQfJjkjycEkT7brja1vktyYZCHJQ0m2T+YuSJJer3GP9H8D+O9V9beBvwc8DuwB7qmqbcA9bR7gYmBbu+wGbhpz25KkEa069JO8DXgPcDNAVX2nqr4F7AT2t277gcva9E7glhq4F9iQ5JxVVy5JGtk4R/pbgUXgPyX5UpLfSfJW4OyqOtL6PAec3aY3Ac8O3f5Qa3uNJLuTzCeZX1xcHKM8SdJS44T+qcB24Kaqeifwf/mLoRwAqqqAGmWlVbW3quaqam5mZmaM8iRJS40T+oeAQ1V1X5v/FIMXgeePDdu066Nt+WFgy9DtN7c2SdKUrDr0q+o54Nkk72hNFwCPAQeAXa1tF3BHmz4AXNk+xXM+8NLQMJAkaQrG/e6dfwHcmuQ04CngAwxeSD6Z5CrgGeD9re9dwCXAAvBy6ytJmqKxQr+qHgTmlll0wTJ9C7h6nO1JksbjGbmS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZNwfUTmpzO6589Xpp6+7dB0rkaS14ZG+JHXE0Jekjhj6ktQRQ1+SOjJ26Cc5JcmXkvy3Nr81yX1JFpJ8Islprf30Nr/Qls+Ou21J0mgmcaT/IeDxofnrgRuq6geBF4GrWvtVwIut/YbWT5I0RWOFfpLNwKXA77T5AD8GfKp12Q9c1qZ3tnna8gtaf0nSlIx7pP/vgY8Af97mzwS+VVWvtPlDwKY2vQl4FqAtf6n1lyRNyapDP8l7gaNVdf8E6yHJ7iTzSeYXFxcnuWpJ6t44R/rvBt6X5GngdgbDOr8BbEhy7EzfzcDhNn0Y2ALQlr8N+ObSlVbV3qqaq6q5mZmZMcqTJC216tCvqo9W1eaqmgUuBz5XVT8FfB74idZtF3BHmz7Q5mnLP1dVtdrtS5JGtxaf0/954JokCwzG7G9u7TcDZ7b2a4A9a7BtSdJxTOQL16rq94Hfb9NPAect0+ePgZ+cxPYkSavjGbmS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjkzk5KyT0eyeO1+dfvq6S9exEkmaHEN/DQy/YIzKFxhJa8nhHUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHPDnrdfDsXEknC4/0Jakjhr4kdWTVoZ9kS5LPJ3ksyaNJPtTaz0hyMMmT7Xpja0+SG5MsJHkoyfZJ3QlJ0uszzpH+K8DPVdW5wPnA1UnOBfYA91TVNuCeNg9wMbCtXXYDN42xbUnSKqw69KvqSFU90Kb/CHgc2ATsBPa3bvuBy9r0TuCWGrgX2JDknFVXLkka2UTG9JPMAu8E7gPOrqojbdFzwNltehPw7NDNDrW2pevanWQ+yfzi4uIkypMkNWOHfpLvBX4X+HBVfXt4WVUVUKOsr6r2VtVcVc3NzMyMW54kachYoZ/kexgE/q1V9enW/PyxYZt2fbS1Hwa2DN18c2uTJE3JOJ/eCXAz8HhV/frQogPArja9C7hjqP3K9ime84GXhoaBJElTMM4Zue8G/hnwcJIHW9svANcBn0xyFfAM8P627C7gEmABeBn4wBjbliStwqpDv6r+F5AVFl+wTP8Crl7t9noxzu/rSjp5rNVXvnhGriR1xC9cG5FfvibpzcwjfUnqiKEvSR0x9CWpI4a+JHXEN3LH4McrJb3ZeKQvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkamHfpIdSZ5IspBkz7S3L0k9m2roJzkF+E3gYuBc4Iok506zBknq2bSP9M8DFqrqqar6DnA7sHPKNUhSt6b9IyqbgGeH5g8B7xrukGQ3sLvN/p8kT4yxvbOAPxzj9mvFukZjXaOxrtG8IevK9WPV9TdXWvCG++WsqtoL7J3EupLMV9XcJNY1SdY1GusajXWNpre6pj28cxjYMjS/ubVJkqZg2qH/RWBbkq1JTgMuBw5MuQZJ6tZUh3eq6pUkHwTuBk4B9lXVo2u4yYkME60B6xqNdY3GukbTVV2pqrVYryTpDcgzciWpI4a+JHXkpAz99fyqhyRbknw+yWNJHk3yodb+S0kOJ3mwXS4Zus1HW61PJLloDWt7OsnDbfvzre2MJAeTPNmuN7b2JLmx1fVQku1rVNM7hvbJg0m+neTD67G/kuxLcjTJI0NtI++fJLta/yeT7Fqjun4tyVfatj+TZENrn03y/4b2228N3eYftMd/odWeNahr5Mdt0n+vK9T1iaGank7yYGuf5v5aKRum+xyrqpPqwuAN4q8BbwdOA74MnDvF7Z8DbG/T3wd8lcFXTvwS8K+X6X9uq/F0YGur/ZQ1qu1p4Kwlbf8G2NOm9wDXt+lLgN8DApwP3Delx+45BieWTH1/Ae8BtgOPrHb/AGcAT7XrjW164xrUdSFwapu+fqiu2eF+S9bzB63WtNovXoO6Rnrc1uLvdbm6liz/d8AvrsP+WikbpvocOxmP9Nf1qx6q6khVPdCm/wh4nMGZyCvZCdxeVX9SVV8HFhjch2nZCexv0/uBy4bab6mBe4ENSc5Z41ouAL5WVc8cp8+a7a+q+gLwwjLbG2X/XAQcrKoXqupF4CCwY9J1VdVnq+qVNnsvg3NeVtRq+/6qurcGyXHL0H2ZWF3HsdLjNvG/1+PV1Y7W3w/cdrx1rNH+WikbpvocOxlDf7mvejhe6K6ZJLPAO4H7WtMH279p+479C8d06y3gs0nuz+DrLgDOrqojbfo54Ox1qOuYy3ntH+N67y8Yff+sx377GQZHhMdsTfKlJP8zyY+0tk2tlmnUNcrjNu399SPA81X15FDb1PfXkmyY6nPsZAz9N4Qk3wv8LvDhqvo2cBPwA8DfB44w+Bdz2n64qrYz+JbTq5O8Z3hhO6JZl8/wZnCy3vuA/9qa3gj76zXWc/+sJMnHgFeAW1vTEeBvVNU7gWuA/5Lk+6dY0hvucVviCl57YDH1/bVMNrxqGs+xkzH01/2rHpJ8D4MH9daq+jRAVT1fVX9WVX8O/DZ/MSQxtXqr6nC7Pgp8ptXw/LFhm3Z9dNp1NRcDD1TV863Gdd9fzaj7Z2r1Jflp4L3AT7WwoA2ffLNN389gvPxvtRqGh4DWpK5VPG7T3F+nAv8E+MRQvVPdX8tlA1N+jp2Mob+uX/XQxgxvBh6vql8fah8eD//HwLFPFhwALk9yepKtwDYGbyBNuq63Jvm+Y9MM3gh8pG3/2Lv/u4A7huq6sn2C4HzgpaF/QdfCa47A1nt/DRl1/9wNXJhkYxvauLC1TVSSHcBHgPdV1ctD7TMZ/G4FSd7OYP881Wr7dpLz23P0yqH7Msm6Rn3cpvn3+uPAV6rq1WGbae6vlbKBaT/Hxnk3+o16YfCu91cZvGp/bMrb/mEG/549BDzYLpcA/xl4uLUfAM4Zus3HWq1PMOYnBI5T19sZfDLiy8Cjx/YLcCZwD/Ak8D+AM1p7GPzgzdda3XNruM/eCnwTeNtQ29T3F4MXnSPAnzIYJ71qNfuHwRj7Qrt8YI3qWmAwrnvsOfZbre8/bY/vg8ADwD8aWs8cgxD+GvAfaGfkT7iukR+3Sf+9LldXa/848LNL+k5zf62UDVN9jvk1DJLUkZNxeEeStAJDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXk/wMlMWLKqyH1AwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocab\n",
        "vocab = set()\n",
        "for sentence in x_train:\n",
        "  for word in sentence:\n",
        "    vocab.add(word)\n",
        "\n",
        "vocab.add('') # for dummy words, to avoid adding a word that has a meaning\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "\n",
        "# Make a mapping betwween words and their IDs\n",
        "word2id = {word:id for  id, word in enumerate(vocab)}\n",
        "id2word = {id:word for  id, word in enumerate(vocab)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3oW2lFyNwwo",
        "outputId": "f207c885-98c3-426e-f251-2de82683c434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 42968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(old_sentence):\n",
        "  encoded_sentence = []\n",
        "  dummy = word2id['']\n",
        "  for word in old_sentence:\n",
        "    try:\n",
        "      encoded_sentence.append(word2id[word])\n",
        "    except KeyError:\n",
        "      encoded_sentence.append(dummy) # the none char\n",
        "\n",
        "  return encoded_sentence"
      ],
      "metadata": {
        "id": "wjEeXJ_uOKIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding train sentences\n",
        "x_train_encoded = []\n",
        "for sentence in x_train:\n",
        "  x_train_encoded.append(encode_sentence(sentence))\n",
        "\n",
        "# Encoding test sentences\n",
        "x_test_encoded = []\n",
        "for sentence in x_test:\n",
        "  x_test_encoded.append(encode_sentence(sentence))\n",
        "\n",
        "print(\"Len train:\", len(x_train_encoded))\n",
        "print(\"Len test:\", len(x_test_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMQx4XRONwAz",
        "outputId": "7daa4912-41dd-4cd5-843b-5a737c6fbbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len train: 6000\n",
            "Len test: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 125\n",
        "dummy = word2id['']\n",
        "# Padding train sentences\n",
        "x_train_padded = pad_sequences(x_train_encoded, maxlen=MAX_SEQ_LEN, dtype='int', padding='post', truncating='post', value=dummy)\n",
        "print(\"Train shape: \",x_train_padded.shape)\n",
        "\n",
        "# Padding test sentences\n",
        "x_test_padded = pad_sequences(x_test_encoded, maxlen=MAX_SEQ_LEN, dtype='int', padding='post', truncating='post', value=dummy)\n",
        "print(\"Test shape: \", x_test_padded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J35A5uNMwEFp",
        "outputId": "75c353c4-a813-4f1f-d4e2-3427153bac78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape:  (6000, 125)\n",
            "Test shape:  (2000, 125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing labels type and shape for training\n",
        "y_train = np.array(y_train)\n",
        "temp, = y_train.shape\n",
        "y_train = y_train.reshape((temp,1))\n",
        "y_train.shape\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "temp, = y_test.shape\n",
        "y_test = y_test.reshape((temp,1))\n",
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKNJKPEbRB-7",
        "outputId": "5d0a4ef4-e21a-47d9-ab5f-bb1c03d87032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Word2Vec Model\n",
        "# glove-twitter-200 model was trained on 2B tweets\n",
        "# with a 1.2M vocab size\n",
        "w2v = api.load('glove-twitter-200')\n",
        "w2v.most_similar(\"mahmoud\")"
      ],
      "metadata": {
        "id": "Gw96ALGpWUX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ace54f6-02be-4fbf-b520-d5ba79c7f0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mohamed', 0.7128403186798096),\n",
              " ('mostafa', 0.6895012259483337),\n",
              " ('ahmed', 0.6817302703857422),\n",
              " ('mohey', 0.6513986587524414),\n",
              " ('ahmadinejad', 0.6093316674232483),\n",
              " ('mohammed', 0.5743428468704224),\n",
              " ('youssef', 0.5647962689399719),\n",
              " ('morsi', 0.554459810256958),\n",
              " ('hassan', 0.5542215704917908),\n",
              " ('fouad', 0.5403571724891663)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an embedding matrix for the embedding layer\n",
        "num_words = len(vocab)\n",
        "embed_size, = w2v['mahmoud'].shape\n",
        "embedding_matrix = np.zeros(shape=(num_words, embed_size))\n",
        "\n",
        "for word, id in word2id.items():\n",
        "  try:\n",
        "    embedding_matrix[id] = w2v[word]\n",
        "  except KeyError:\n",
        "    embedding_matrix[id] = np.zeros(embed_size)\n",
        "\n",
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3efCTKYR2FS",
        "outputId": "b0654445-c1c1-49b8-ac49-c14b6a59c5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42968, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() # Makes sure old model was deleted if exists\n",
        "\n",
        "# create model\n",
        "lstm_model = Sequential(name='Rating')\n",
        "\n",
        "lstm_model.add(Input(shape=(MAX_SEQ_LEN,), dtype='int32'))\n",
        "lstm_model.add(Embedding(input_dim = len(vocab),            # Vocabulary Size (number of unique words for training)\n",
        "                        output_dim = embed_size,            # Length of the vector for each word (embedding dimension)\n",
        "                        input_length = MAX_SEQ_LEN,         # Maximum length of a sequence\n",
        "                        weights = [embedding_matrix],       # Send the needed glove-twitter-200 Weights\n",
        "                        trainable = False))\n",
        "\n",
        "lstm_model.add(LSTM(units = 30, \n",
        "                    return_sequences=True, \n",
        "                    # dropout=0.5, \n",
        "                    # recurrent_dropout=0.5\n",
        "                    )\n",
        "              )\n",
        "lstm_model.add(LSTM(units = 30, \n",
        "                    # return_sequences=True,\n",
        "                    # dropout=0.5, \n",
        "                    # recurrent_dropout=0.5\n",
        "                    )\n",
        "              )\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999), \n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLpBG8woTh_P",
        "outputId": "dd4aa478-eddf-495c-a18d-abe284f67751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Rating\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 125, 200)          8593600   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 125, 30)           27720     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 30)                7320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,628,671\n",
            "Trainable params: 35,071\n",
            "Non-trainable params: 8,593,600\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels = shuffle(x_train_padded, y_train, random_state=42)"
      ],
      "metadata": {
        "id": "7DqbYdfiexO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save('lstm_w_770.h5',save_format='h5')"
      ],
      "metadata": {
        "id": "3Tl77o5wC-c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(train_data, \n",
        "               train_labels, \n",
        "               validation_split=0.20, \n",
        "               batch_size = 50,\n",
        "               epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fDtA51kWjHs",
        "outputId": "526dbd4e-f3d8-4549-a7e4-a631aa0c4f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "96/96 [==============================] - 10s 80ms/step - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6904 - val_accuracy: 0.5275\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.6904 - accuracy: 0.5312 - val_loss: 0.6895 - val_accuracy: 0.5292\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.6886 - accuracy: 0.5360 - val_loss: 0.6886 - val_accuracy: 0.5333\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.6857 - accuracy: 0.5417 - val_loss: 0.6872 - val_accuracy: 0.5325\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.6804 - accuracy: 0.5475 - val_loss: 0.6860 - val_accuracy: 0.5308\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.6716 - accuracy: 0.5577 - val_loss: 0.6816 - val_accuracy: 0.5567\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.6404 - accuracy: 0.6540 - val_loss: 0.6274 - val_accuracy: 0.6758\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.5943 - accuracy: 0.6979 - val_loss: 0.6034 - val_accuracy: 0.6975\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.5752 - accuracy: 0.7181 - val_loss: 0.5704 - val_accuracy: 0.7258\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 7s 73ms/step - loss: 0.5518 - accuracy: 0.7387 - val_loss: 0.5615 - val_accuracy: 0.7308\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.5342 - accuracy: 0.7508 - val_loss: 0.5428 - val_accuracy: 0.7500\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.5170 - accuracy: 0.7654 - val_loss: 0.5323 - val_accuracy: 0.7525\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.5050 - accuracy: 0.7742 - val_loss: 0.5232 - val_accuracy: 0.7533\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4917 - accuracy: 0.7865 - val_loss: 0.5247 - val_accuracy: 0.7567\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4847 - accuracy: 0.7873 - val_loss: 0.5185 - val_accuracy: 0.7625\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4725 - accuracy: 0.7948 - val_loss: 0.5175 - val_accuracy: 0.7617\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4662 - accuracy: 0.7950 - val_loss: 0.5026 - val_accuracy: 0.7725\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4593 - accuracy: 0.8006 - val_loss: 0.5062 - val_accuracy: 0.7683\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.4528 - accuracy: 0.8067 - val_loss: 0.4991 - val_accuracy: 0.7750\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4418 - accuracy: 0.8092 - val_loss: 0.4975 - val_accuracy: 0.7717\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4359 - accuracy: 0.8165 - val_loss: 0.4914 - val_accuracy: 0.7792\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4292 - accuracy: 0.8200 - val_loss: 0.4955 - val_accuracy: 0.7725\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 7s 73ms/step - loss: 0.4210 - accuracy: 0.8269 - val_loss: 0.4891 - val_accuracy: 0.7775\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4122 - accuracy: 0.8310 - val_loss: 0.4893 - val_accuracy: 0.7742\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 7s 73ms/step - loss: 0.4124 - accuracy: 0.8327 - val_loss: 0.4895 - val_accuracy: 0.7858\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.4026 - accuracy: 0.8396 - val_loss: 0.4857 - val_accuracy: 0.7775\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3967 - accuracy: 0.8408 - val_loss: 0.4917 - val_accuracy: 0.7783\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3912 - accuracy: 0.8413 - val_loss: 0.4882 - val_accuracy: 0.7858\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3874 - accuracy: 0.8456 - val_loss: 0.4842 - val_accuracy: 0.7808\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3773 - accuracy: 0.8550 - val_loss: 0.5050 - val_accuracy: 0.7758\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 8s 79ms/step - loss: 0.3754 - accuracy: 0.8523 - val_loss: 0.4944 - val_accuracy: 0.7883\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3684 - accuracy: 0.8546 - val_loss: 0.4864 - val_accuracy: 0.7792\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3613 - accuracy: 0.8623 - val_loss: 0.5007 - val_accuracy: 0.7825\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3527 - accuracy: 0.8685 - val_loss: 0.5083 - val_accuracy: 0.7808\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3468 - accuracy: 0.8706 - val_loss: 0.5126 - val_accuracy: 0.7775\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3405 - accuracy: 0.8725 - val_loss: 0.5172 - val_accuracy: 0.7783\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3306 - accuracy: 0.8804 - val_loss: 0.5160 - val_accuracy: 0.7842\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3339 - accuracy: 0.8788 - val_loss: 0.5265 - val_accuracy: 0.7758\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3351 - accuracy: 0.8783 - val_loss: 0.5116 - val_accuracy: 0.7858\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3266 - accuracy: 0.8810 - val_loss: 0.5283 - val_accuracy: 0.7858\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3158 - accuracy: 0.8881 - val_loss: 0.5298 - val_accuracy: 0.7833\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3362 - accuracy: 0.8737 - val_loss: 0.5301 - val_accuracy: 0.7867\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.3130 - accuracy: 0.8900 - val_loss: 0.5275 - val_accuracy: 0.7808\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3069 - accuracy: 0.8919 - val_loss: 0.5417 - val_accuracy: 0.7808\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3085 - accuracy: 0.8913 - val_loss: 0.5426 - val_accuracy: 0.7808\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.2984 - accuracy: 0.8967 - val_loss: 0.5336 - val_accuracy: 0.7892\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.2953 - accuracy: 0.9006 - val_loss: 0.5377 - val_accuracy: 0.7883\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 7s 74ms/step - loss: 0.2986 - accuracy: 0.8981 - val_loss: 0.5609 - val_accuracy: 0.7808\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3043 - accuracy: 0.8958 - val_loss: 0.5249 - val_accuracy: 0.7825\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 7s 75ms/step - loss: 0.3039 - accuracy: 0.8960 - val_loss: 0.5282 - val_accuracy: 0.7867\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0eccc42d10>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l, a = lstm_model.evaluate(x_test_padded, y_test)\n",
        "print(\"Test accuracy:\", round(a*100,2),\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdGdLtj6-W3l",
        "outputId": "6fa5695a-4c71-4cc5-d6d4-65cd0310c4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 20ms/step - loss: 0.5951 - accuracy: 0.7700\n",
            "Test accuracy: 77.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom function to predict sentences\n",
        "def lstm_predict(sentence:str):\n",
        "  sentence = clean_sentence(sentence)\n",
        "  # Encode sentence\n",
        "  ready_sentence = encode_sentence(sentence)\n",
        "  # Padding sentence\n",
        "  ready_sentence = pad_sequences(sequences = [ready_sentence], \n",
        "                                 maxlen=MAX_SEQ_LEN,\n",
        "                                 dtype='int32', \n",
        "                                 padding='post',\n",
        "                                 truncating='post',\n",
        "                                 value = dummy)\n",
        "  \n",
        "  # Predict\n",
        "  prediction = round(lstm_model.predict(ready_sentence)[0][0])\n",
        "  if prediction==0:\n",
        "    print(\"Negative Review\")\n",
        "  elif prediction==1:\n",
        "    print(\"Positive Review\")\n",
        "  else:\n",
        "    print('Error')\n",
        "  "
      ],
      "metadata": {
        "id": "xMECijfG-9Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Straight forward positive\n",
        "lstm_predict(\"I really recommend this book\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZRaAIAyAJ8d",
        "outputId": "eb67b517-ffec-4fea-ae3a-775aa290be4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tricky positive\n",
        "lstm_predict(\"The dvd included a big poster of my favorite hero. I just can't wait for the second episode\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU0ncSNdLyd8",
        "outputId": "885ba82a-5d45-4035-caa7-f4b1b3c4d406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Straight forward negative\n",
        "lstm_predict(\"I don't know what the hell did i just read, the book is full nonsense\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "webUt6U5Hlt3",
        "outputId": "4cb94c4f-d442-4943-abdc-1cb708117a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tricky negative\n",
        "lstm_predict(\"The book is very huge with too much unnecessary details that could have been omitted. Just buy another book!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdx76wmGMuoa",
        "outputId": "8697f919-cd4c-4ee0-f137-3857dbf09965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Review\n"
          ]
        }
      ]
    }
  ]
}